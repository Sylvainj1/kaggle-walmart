{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implémentation du RMSSE (weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "      <th>d_1914</th>\n",
       "      <th>d_1915</th>\n",
       "      <th>d_1916</th>\n",
       "      <th>d_1917</th>\n",
       "      <th>d_1918</th>\n",
       "      <th>d_1919</th>\n",
       "      <th>d_1920</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_1911  d_1912  d_1913  d_1914  d_1915  d_1916  d_1917  d_1918  d_1919  \\\n",
       "0       0       1       1       0       0       0       2       0       3   \n",
       "1       0       0       0       0       1       0       0       0       0   \n",
       "2       1       1       1       0       0       1       1       0       2   \n",
       "3       3       7       2       0       0       1       2       4       1   \n",
       "4       2       2       4       1       0       2       3       1       0   \n",
       "\n",
       "   d_1920  ...  d_1932  d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  \\\n",
       "0       5  ...       2       4       0       0       0       0       3   \n",
       "1       0  ...       0       1       2       1       1       0       0   \n",
       "2       1  ...       1       0       2       0       0       0       2   \n",
       "3       6  ...       1       1       0       4       0       1       3   \n",
       "4       3  ...       0       0       0       2       1       0       0   \n",
       "\n",
       "   d_1939  d_1940  d_1941  \n",
       "0       3       0       1  \n",
       "1       0       0       0  \n",
       "2       3       0       1  \n",
       "3       0       2       6  \n",
       "4       2       1       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/data/sales_train_evaluation.csv\")\n",
    "df_train_full.iloc[:, -31:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        \n",
    "        # 28 derniers jours pour le poids\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 0  # lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'cat_id',\n",
    "            'state_id',\n",
    "            'dept_id',\n",
    "            'store_id',\n",
    "            'item_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        group_ids = []\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            group_ids.append(group_id)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "\n",
    "        return group_ids, all_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## public LB rank\n",
    "def get_lb_rank(score):\n",
    "    \"\"\"\n",
    "    score de la LB depuis le fichier de la leaderboard fourni par kaggle\n",
    "    \"\"\"\n",
    "    df_lb = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/data/datasets_687702_1205782_m5-forecasting-accuracy-publicleaderboard-rank.csv\")\n",
    "\n",
    "    return (df_lb.Score <= score).sum() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d959895e43e84b4584ef66f6b691a78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## reading data\n",
    "df_calendar = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/data/calendar.csv\")\n",
    "df_prices = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/data/sell_prices.csv\")\n",
    "df_sample_submission = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/data/sample_submission.csv\")\n",
    "df_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n",
    "\n",
    "df_train = df_train_full.iloc[:, :-28]\n",
    "df_valid = df_train_full.iloc[:, -28:]\n",
    "\n",
    "evaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1914</th>\n",
       "      <th>d_1915</th>\n",
       "      <th>d_1916</th>\n",
       "      <th>d_1917</th>\n",
       "      <th>d_1918</th>\n",
       "      <th>d_1919</th>\n",
       "      <th>d_1920</th>\n",
       "      <th>d_1921</th>\n",
       "      <th>d_1922</th>\n",
       "      <th>d_1923</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>63</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>98</td>\n",
       "      <td>39</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>68</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>77</td>\n",
       "      <td>99</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_1914  d_1915  d_1916  d_1917  d_1918  d_1919  d_1920  d_1921  d_1922  \\\n",
       "0      97      22       4      43      22      13      11      26      15   \n",
       "1      35      22      52      63      92       9      62      71       5   \n",
       "2      48      46       8      12      98       2      59      13      30   \n",
       "3       1      60      42      40      11      84      20      18      42   \n",
       "4      72      77      99      67       9      41      48      39      49   \n",
       "\n",
       "   d_1923  ...  d_1932  d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  \\\n",
       "0      89  ...      67      41       7      26      93      23      72   \n",
       "1      38  ...      41       3      47      12      18       4      43   \n",
       "2      83  ...      31      25       7      27      34      98      39   \n",
       "3      90  ...      86      94      23      79      14      29      68   \n",
       "4      99  ...      36      19      60      78      41      81       3   \n",
       "\n",
       "   d_1939  d_1940  d_1941  \n",
       "0      83      18      45  \n",
       "1      11      54      51  \n",
       "2      53      17      41  \n",
       "3      50      37      77  \n",
       "4       5      60      20  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## structure de validation\n",
    "# les F1 - F28 sont remplacés par leur véritables valeur d_1914 -> d_1941\n",
    "preds_valid = df_valid.copy() + np.random.randint(100, size = df_valid.shape)\n",
    "preds_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.81167\n",
      "Score for group cat_id: 0.81156\n",
      "Score for group state_id: 0.80682\n",
      "Score for group dept_id: 0.86382\n",
      "Score for group store_id: 0.83913\n",
      "Score for group item_id: 0.99046\n",
      "Score for group ['state_id', 'cat_id']: 0.82135\n",
      "Score for group ['state_id', 'dept_id']: 0.85618\n",
      "Score for group ['store_id', 'cat_id']: 0.85852\n",
      "Score for group ['store_id', 'dept_id']: 0.88607\n",
      "Score for group ['item_id', 'state_id']: 0.93917\n",
      "Score for group ['item_id', 'store_id']: 0.89277\n",
      "\n",
      "Public LB Score: 0.86479\n",
      "Public LB Rank: 3559\n"
     ]
    }
   ],
   "source": [
    "#SCORE PROPHET DE BASE SANS TUNING NI REGRESSOR EN PLUS\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/submission/submission_prophet2_ALL.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.22446\n",
      "Score for group cat_id: 0.28115\n",
      "Score for group state_id: 0.31021\n",
      "Score for group dept_id: 0.36466\n",
      "Score for group store_id: 0.4162\n",
      "Score for group item_id: 0.80661\n",
      "Score for group ['state_id', 'cat_id']: 0.37909\n",
      "Score for group ['state_id', 'dept_id']: 0.46331\n",
      "Score for group ['store_id', 'cat_id']: 0.48759\n",
      "Score for group ['store_id', 'dept_id']: 0.57376\n",
      "Score for group ['item_id', 'state_id']: 0.81841\n",
      "Score for group ['item_id', 'store_id']: 0.82496\n",
      "\n",
      "Public LB Score: 0.49587\n",
      "Public LB Rank: 1698\n"
     ]
    }
   ],
   "source": [
    "# SCORE LIGHTGBM AVEC LES LAGS et ALPHA CHANGEANT POUR EVITER OVERFITTING\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/submission/submission_1_all_data.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.23689\n",
      "Score for group cat_id: 0.29054\n",
      "Score for group state_id: 0.32037\n",
      "Score for group dept_id: 0.37282\n",
      "Score for group store_id: 0.42771\n",
      "Score for group item_id: 0.80696\n",
      "Score for group ['state_id', 'cat_id']: 0.38572\n",
      "Score for group ['state_id', 'dept_id']: 0.46951\n",
      "Score for group ['store_id', 'cat_id']: 0.49558\n",
      "Score for group ['store_id', 'dept_id']: 0.58178\n",
      "Score for group ['item_id', 'state_id']: 0.819\n",
      "Score for group ['item_id', 'store_id']: 0.82556\n",
      "\n",
      "Public LB Score: 0.5027\n",
      "Public LB Rank: 1789\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# SCORE LIGHTGBM AVEC LES LAGS et ALPHA CHANGEANT POUR EVITER OVERFITTING\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/submission/submission_hugo_lightGBM.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.32808\n",
      "Score for group cat_id: 0.36123\n",
      "Score for group state_id: 0.40072\n",
      "Score for group dept_id: 0.45352\n",
      "Score for group store_id: 0.47683\n",
      "Score for group item_id: 0.85941\n",
      "Score for group ['state_id', 'cat_id']: 0.44934\n",
      "Score for group ['state_id', 'dept_id']: 0.53176\n",
      "Score for group ['store_id', 'cat_id']: 0.53543\n",
      "Score for group ['store_id', 'dept_id']: 0.61711\n",
      "Score for group ['item_id', 'state_id']: 0.85519\n",
      "Score for group ['item_id', 'store_id']: 0.8493\n",
      "\n",
      "Public LB Score: 0.55983\n",
      "Public LB Rank: 2198\n"
     ]
    }
   ],
   "source": [
    "#SCORE PROPHET et mlighGBM mean\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/submission/submission_mean_p_l.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_w_eval = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/submission/prophet_tuned_without_eval_computed.csv\")\n",
    "p_w_eval = p_w_eval.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.50495\n",
      "Score for group cat_id: 0.52624\n",
      "Score for group state_id: 0.55787\n",
      "Score for group dept_id: 0.62018\n",
      "Score for group store_id: 0.6205\n",
      "Score for group item_id: 1.0094\n",
      "Score for group ['state_id', 'cat_id']: 0.59602\n",
      "Score for group ['state_id', 'dept_id']: 0.67504\n",
      "Score for group ['store_id', 'cat_id']: 0.668\n",
      "Score for group ['store_id', 'dept_id']: 0.74063\n",
      "Score for group ['item_id', 'state_id']: 0.96692\n",
      "Score for group ['item_id', 'store_id']: 0.93122\n",
      "\n",
      "Public LB Score: 0.70141\n",
      "Public LB Rank: 3144\n"
     ]
    }
   ],
   "source": [
    "#SCORE PROPHET TUNED MAIS SANS LE CALUL DE L'EVAL, JUSTE LA VALIDATION\n",
    "\n",
    "preds_valid = p_w_eval\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/submission/test_metric_computation.csv\")\n",
    "test_metric = test_metric.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.50495\n",
      "Score for group cat_id: 0.52624\n",
      "Score for group state_id: 0.55787\n",
      "Score for group dept_id: 0.62018\n",
      "Score for group store_id: 0.6205\n",
      "Score for group item_id: 1.0094\n",
      "Score for group ['state_id', 'cat_id']: 0.59602\n",
      "Score for group ['state_id', 'dept_id']: 0.67504\n",
      "Score for group ['store_id', 'cat_id']: 0.668\n",
      "Score for group ['store_id', 'dept_id']: 0.74063\n",
      "Score for group ['item_id', 'state_id']: 0.96692\n",
      "Score for group ['item_id', 'store_id']: 0.93122\n",
      "\n",
      "Public LB Score: 0.70141\n",
      "Public LB Rank: 3144\n"
     ]
    }
   ],
   "source": [
    "#TEST DE LA METRIC POUR SAVOIR SI DANS LE CALCUL DU LB PUBLIC IL Y A L'EVAL OU JUSTE LA VALIDATION\n",
    "# IL S'AGIT ICI D'UN DATASET AVEC QUE DES 0 DANS LA PARTIE EVAL POUR POUVOIR CALCULER AVEC LE SCORRE D'AU DESSUS\n",
    "\n",
    "preds_valid = test_metric\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LE SCORE EST LE MEME PAR CONSEQUENT PAS BESOIN DE COMPUTE LA PARTIE EVAL CA SAVE DU TEMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/kaggle_walmart/model/mean_prophet_light_lighthugo.csv' does not exist: b'/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/kaggle_walmart/model/mean_prophet_light_lighthugo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3fdc15bbfec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# IL S'AGIT ICI D'UN DATASET AVEC QUE DES 0 DANS LA PARTIE EVAL POUR POUVOIR CALCULER AVEC LE SCORRE D'AU DESSUS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/kaggle_walmart/model/mean_prophet_light_lighthugo.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpreds_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpreds_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/kaggle_walmart/model/mean_prophet_light_lighthugo.csv' does not exist: b'/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/kaggle_walmart/model/mean_prophet_light_lighthugo.csv'"
     ]
    }
   ],
   "source": [
    "#TEST DE LA METRIC POUR SAVOIR SI DANS LE CALCUL DU LB PUBLIC IL Y A L'EVAL OU JUSTE LA VALIDATION\n",
    "# IL S'AGIT ICI D'UN DATASET AVEC QUE DES 0 DANS LA PARTIE EVAL POUR POUVOIR CALCULER AVEC LE SCORRE D'AU DESSUS\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/kaggle_walmart/model/mean_prophet_light_lighthugo.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerem/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "submission_sample = pd.read_csv('/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/data/sample_submission.csv')\n",
    "fourier = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/fourier_each_item.csv\")\n",
    "fourier_all = pd.concat([fourier, submission_sample[30490:]], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649667</td>\n",
       "      <td>0.632877</td>\n",
       "      <td>1.072808</td>\n",
       "      <td>0.950150</td>\n",
       "      <td>0.314333</td>\n",
       "      <td>0.851343</td>\n",
       "      <td>0.429533</td>\n",
       "      <td>0.114580</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035258</td>\n",
       "      <td>2.069586</td>\n",
       "      <td>1.170895</td>\n",
       "      <td>0.475853</td>\n",
       "      <td>1.282107</td>\n",
       "      <td>1.138495</td>\n",
       "      <td>1.350810</td>\n",
       "      <td>1.495057</td>\n",
       "      <td>1.139127</td>\n",
       "      <td>FOODS_1_001_CA_2_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055270</td>\n",
       "      <td>1.361907</td>\n",
       "      <td>1.266157</td>\n",
       "      <td>0.705037</td>\n",
       "      <td>0.366896</td>\n",
       "      <td>1.055044</td>\n",
       "      <td>1.559367</td>\n",
       "      <td>0.597559</td>\n",
       "      <td>1.880193</td>\n",
       "      <td>FOODS_1_001_CA_3_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557659</td>\n",
       "      <td>0.304791</td>\n",
       "      <td>0.622486</td>\n",
       "      <td>0.276241</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.300178</td>\n",
       "      <td>0.257675</td>\n",
       "      <td>0.160741</td>\n",
       "      <td>FOODS_1_001_CA_4_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334654</td>\n",
       "      <td>0.292669</td>\n",
       "      <td>0.999014</td>\n",
       "      <td>0.418376</td>\n",
       "      <td>0.200649</td>\n",
       "      <td>0.935617</td>\n",
       "      <td>0.277866</td>\n",
       "      <td>0.395747</td>\n",
       "      <td>0.376730</td>\n",
       "      <td>FOODS_1_001_TX_1_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows × 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        F1  F10  F11  F12  F13  F14  F15  F16  F17  F18  ...    d_1905  \\\n",
       "0      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  0.649667   \n",
       "1      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  1.035258   \n",
       "2      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  1.055270   \n",
       "3      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  0.557659   \n",
       "4      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  0.334654   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "60975  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
       "60976  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
       "60977  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
       "60978  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
       "60979  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
       "\n",
       "         d_1906    d_1907    d_1908    d_1909    d_1910    d_1911    d_1912  \\\n",
       "0      0.632877  1.072808  0.950150  0.314333  0.851343  0.429533  0.114580   \n",
       "1      2.069586  1.170895  0.475853  1.282107  1.138495  1.350810  1.495057   \n",
       "2      1.361907  1.266157  0.705037  0.366896  1.055044  1.559367  0.597559   \n",
       "3      0.304791  0.622486  0.276241  0.216536  0.846667  0.300178  0.257675   \n",
       "4      0.292669  0.999014  0.418376  0.200649  0.935617  0.277866  0.395747   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "60975       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "60976       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "60977       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "60978       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "60979       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "         d_1913                           id  \n",
       "0      0.741544  FOODS_1_001_CA_1_validation  \n",
       "1      1.139127  FOODS_1_001_CA_2_validation  \n",
       "2      1.880193  FOODS_1_001_CA_3_validation  \n",
       "3      0.160741  FOODS_1_001_CA_4_validation  \n",
       "4      0.376730  FOODS_1_001_TX_1_validation  \n",
       "...         ...                          ...  \n",
       "60975       NaN  FOODS_3_823_WI_3_evaluation  \n",
       "60976       NaN  FOODS_3_824_WI_3_evaluation  \n",
       "60977       NaN  FOODS_3_825_WI_3_evaluation  \n",
       "60978       NaN  FOODS_3_826_WI_3_evaluation  \n",
       "60979       NaN  FOODS_3_827_WI_3_evaluation  \n",
       "\n",
       "[60980 rows x 395 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourier_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c4ff1c2cb7db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m }, inplace = True)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mscore_public_lb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-67e785fd205b>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, valid_preds)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_target_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalid_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SCORE FOURIER SUR CHACUN DES ITEMS\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/fourier_each_item.csv\")\n",
    "preds_valid = preds_valid.reset_index()\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 0.50615\n",
      "Score for group cat_id: 0.52848\n",
      "Score for group state_id: 0.55781\n",
      "Score for group dept_id: 0.6231\n",
      "Score for group store_id: 0.62012\n",
      "Score for group item_id: 1.01146\n",
      "Score for group ['state_id', 'cat_id']: 0.59698\n",
      "Score for group ['state_id', 'dept_id']: 0.67686\n",
      "Score for group ['store_id', 'cat_id']: 0.6697\n",
      "Score for group ['store_id', 'dept_id']: 0.74324\n",
      "Score for group ['item_id', 'state_id']: 0.96854\n",
      "Score for group ['item_id', 'store_id']: 0.93169\n",
      "\n",
      "Public LB Score: 0.70284\n",
      "Public LB Rank: 3148\n"
     ]
    }
   ],
   "source": [
    "#SCORE FOURIER SUR CHACUN DES ITEMS\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/submission/submission_prophet_store.csv\")\n",
    "#preds_valid = preds_valid.reset_index()\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 7.50597\n",
      "Score for group cat_id: 7.2123\n",
      "Score for group state_id: 6.88219\n",
      "Score for group dept_id: 7.02579\n",
      "Score for group store_id: 6.52817\n",
      "Score for group item_id: 2.71747\n",
      "Score for group ['state_id', 'cat_id']: 6.48894\n",
      "Score for group ['state_id', 'dept_id']: 6.21863\n",
      "Score for group ['store_id', 'cat_id']: 5.91125\n",
      "Score for group ['store_id', 'dept_id']: 5.46313\n",
      "Score for group ['item_id', 'state_id']: 1.97804\n",
      "Score for group ['item_id', 'store_id']: 1.412\n",
      "\n",
      "Public LB Score: 5.44532\n",
      "Public LB Rank: 4405\n"
     ]
    }
   ],
   "source": [
    "#SCORE LIGHT ET FOURIER\n",
    "\n",
    "preds_valid = pd.read_csv(\"/Users/jerem/cours_esiee_paris/E4/kaggle_walmart/kaggle_walmart/model/submission_with_fourier.csv\")\n",
    "#preds_valid = preds_valid.reset_index()\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsse(y_true, y_pred, y_hist):\n",
    "    h, n = len(y_true), len(y_hist)\n",
    "\n",
    "    numerateur = np.sum((y_true - y_pred)**2)\n",
    "    denominateur = 1/(n-1)*np.sum((y_hist[1:] - y_hist[:-1])**2)\n",
    "\n",
    "    rmsse = np.sqrt(1/h * numerateur/denominateur)\n",
    "    return rmsse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
